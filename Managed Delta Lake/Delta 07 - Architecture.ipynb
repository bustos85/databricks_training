{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Architecture\n",
    "\n",
    "The Lambda architecture is a big data processing architecture that combines both batch and real-time processing methods.\n",
    "It features an append-only immutable data source that serves as system of record. Timestamped events are appended to \n",
    "existing events (nothing is overwritten). Data is implicitly ordered by time of arrival. \n",
    "\n",
    "Notice how there are really two pipelines here, one batch and one streaming, hence the name <i>lambda</i> architecture.\n",
    "\n",
    "It is very difficult to combine processing of batch and real-time data as is evidenced by the diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks Delta Architecture\n",
    "\n",
    "The Databricks Delta Architecture is a vast improvement upon the traditional Lambda architecture.\n",
    "\n",
    "Text files, RDBMS data and streaming data is all collected into a <b>raw</b> table (also known as \"bronze\" tables at Databricks).\n",
    "\n",
    "A Raw table is then parsed into <b>query</b> tables (also known as \"silver\" tables at Databricks). They may be joined with dimension tables.\n",
    "\n",
    "<b>Summary</b> tables (also known as \"gold\" tables at Databricks) are business level aggregates often used for reporting and dashboarding. \n",
    "This would include aggregations such as daily active website users.\n",
    "\n",
    "The end outputs are actionable insights, dashboards and reports of business metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databricks Delta Architecture\n",
    "\n",
    "We use terminology \n",
    "* \"bronze\" (instead of \"raw\"), \n",
    "* \"silver\" (instead of \"query\"), \n",
    "* \"gold\" (instead of \"summary\"), \n",
    "* \"platinum\" (another level of refinement)\n",
    "\n",
    "This is not standard in the industry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up relevant paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bronzePath           = workingDir + \"/wikipedia/bronze.delta\"\n",
    "bronzeCheckpointPath = workingDir + \"/wikipedia/bronze.checkpoint\"\n",
    "\n",
    "silverPath           = workingDir + \"/wikipedia/silver.delta\"\n",
    "silverCheckpointPath = workingDir + \"/wikipedia/silver.checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to help us manage our streams better, we will make use of **`untilStreamIsReady()`**, **`stopAllStreams()`** and define the following, **`bronzeStreamName`**, **`silverStreamName`** and **`goldStreamName`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bronzeStreamName = \"bronze_stream_ps\"\n",
    "silverStreamName = \"silver_stream_ps\"\n",
    "goldStreamName = \"gold_stream_ps\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to RAW table (aka \"bronze table\")\n",
    "\n",
    "<b>Raw data</b> is unaltered data that is collected into a data lake, either via bulk upload or through streaming sources.\n",
    "\n",
    "The following function reads the Wikipedia IRC channels that has been dumped into our Kafka server.\n",
    "\n",
    "The Kafka server acts as a sort of \"firehose\" and dumps raw data into our data lake.\n",
    "\n",
    "Below, the first step is to set up schema. The fields we use further down in the notebook are commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "\n",
    "schema = StructType([\n",
    "  StructField(\"channel\", StringType(), True),\n",
    "  StructField(\"comment\", StringType(), True),\n",
    "  StructField(\"delta\", IntegerType(), True),\n",
    "  StructField(\"flag\", StringType(), True),\n",
    "  StructField(\"geocoding\", StructType([                 # (OBJECT): Added by the server, field contains IP address geocoding information for anonymous edit.\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"countryCode2\", StringType(), True),\n",
    "    StructField(\"countryCode3\", StringType(), True),\n",
    "    StructField(\"stateProvince\", StringType(), True),\n",
    "    StructField(\"latitude\", DoubleType(), True),\n",
    "    StructField(\"longitude\", DoubleType(), True),\n",
    "  ]), True),\n",
    "  StructField(\"isAnonymous\", BooleanType(), True),      # (BOOLEAN): Whether or not the change was made by an anonymous user\n",
    "  StructField(\"isNewPage\", BooleanType(), True),\n",
    "  StructField(\"isRobot\", BooleanType(), True),\n",
    "  StructField(\"isUnpatrolled\", BooleanType(), True),\n",
    "  StructField(\"namespace\", StringType(), True),         # (STRING): Page's namespace. See https://en.wikipedia.org/wiki/Wikipedia:Namespace \n",
    "  StructField(\"page\", StringType(), True),              # (STRING): Printable name of the page that was edited\n",
    "  StructField(\"pageURL\", StringType(), True),           # (STRING): URL of the page that was edited\n",
    "  StructField(\"timestamp\", StringType(), True),         # (STRING): Time the edit occurred, in ISO-8601 format\n",
    "  StructField(\"url\", StringType(), True),\n",
    "  StructField(\"user\", StringType(), True),              # (STRING): User who made the edit or the IP address associated with the anonymous editor\n",
    "  StructField(\"userURL\", StringType(), True),\n",
    "  StructField(\"wikipediaURL\", StringType(), True),\n",
    "  StructField(\"wikipedia\", StringType(), True),         # (STRING): Short name of the Wikipedia that was edited (e.g., \"en\" for the English)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, stream into bronze Databricks Delta directory.\n",
    "\n",
    "Notice how we are invoking the `.start(path)` method. \n",
    "\n",
    "This is so that the data is streamed into the path we want (and not a default directory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f25893a7be0&gt;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "(spark.readStream\n",
    "  .format(\"kafka\")  \n",
    "  .option(\"kafka.bootstrap.servers\", \"server1.databricks.training:9092\")  # Oregon\n",
    "  #.option(\"kafka.bootstrap.servers\", \"server2.databricks.training:9092\") # Singapore\n",
    "  .option(\"subscribe\", \"en\")\n",
    "  .load()\n",
    "  .withColumn(\"json\", from_json(col(\"value\").cast(\"string\"), schema))\n",
    "  .select(col(\"timestamp\").alias(\"kafka_timestamp\"), col(\"json.*\"))\n",
    "  .writeStream\n",
    "  .format(\"delta\")\n",
    "  .option(\"checkpointLocation\", bronzeCheckpointPath)\n",
    "  .outputMode(\"append\")\n",
    "  .queryName(bronzeStreamName)\n",
    "  .start(bronzePath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream bronze_stream_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wait until the stream is done initializing...\n",
    "untilStreamIsReady(bronzeStreamName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look the first row of the raw table without explicitly creating a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>kafka_timestamp</th><th>channel</th><th>comment</th><th>delta</th><th>flag</th><th>geocoding</th><th>isAnonymous</th><th>isNewPage</th><th>isRobot</th><th>isUnpatrolled</th><th>namespace</th><th>page</th><th>pageURL</th><th>timestamp</th><th>url</th><th>user</th><th>userURL</th><th>wikipediaURL</th><th>wikipedia</th></tr></thead><tbody><tr><td>1969-12-31T23:59:59.999+0000</td><td>#en.wikipedia</td><td>/* Comparison */</td><td>13</td><td></td><td>List(null, null, null, null, null, null, null)</td><td>false</td><td>false</td><td>false</td><td>false</td><td>article</td><td>DOCSIS</td><td>http://en.wikipedia.org/wiki/DOCSIS</td><td>2020-04-15T10:46:28.513Z</td><td>https://en.wikipedia.org/w/index.php?diff=951077732&oldid=950219702</td><td>Xose.vazquez</td><td>http://en.wikipedia.org/wiki/User:Xose.vazquez</td><td>http://en.wikipedia.org</td><td>en</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bronzeDF = spark.sql(f\"SELECT * FROM delta.`{bronzePath}` limit 1\")\n",
    "display(bronzeDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create QUERY tables (aka \"silver tables\")\n",
    "\n",
    "Notice how `WikipediaEditsRaw` has JSON encoding. For example `{\"city\":null,\"country\":null,\"countryCode2\":null,\"c..`\n",
    "\n",
    "In order to be able parse the data in human-readable form, create query tables out of the raw data using columns<br>\n",
    "`wikipedia`, `isAnonymous`, `namespace`, `page`, `pageURL`, `geocoding`, `timestamp` and `user`.\n",
    "\n",
    "Stream into a Databricks Delta query directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[19]: &lt;pyspark.sql.streaming.StreamingQuery at 0x7f25876bbdd8&gt;</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp, col\n",
    "\n",
    "(spark.readStream\n",
    "  .format(\"delta\")\n",
    "  .load(bronzePath)\n",
    "  .select(col(\"wikipedia\"),\n",
    "          col(\"isAnonymous\"),\n",
    "          col(\"namespace\"),\n",
    "          col(\"page\"),\n",
    "          col(\"pageURL\"),\n",
    "          col(\"geocoding\"),\n",
    "          unix_timestamp(col(\"timestamp\"), \"yyyy-MM-dd'T'HH:mm:ss.SSSX\").cast(\"timestamp\").alias(\"timestamp\"),\n",
    "          col(\"user\"))\n",
    "  .writeStream\n",
    "  .format(\"delta\")\n",
    "  .option(\"checkpointLocation\", silverCheckpointPath)\n",
    "  .outputMode(\"append\")\n",
    "  .queryName(silverStreamName)\n",
    "  .start(silverPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream silver_stream_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wait until the stream is done initializing...\n",
    "untilStreamIsReady(silverStreamName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at the streaming query view without explicitly creating tables.\n",
    "\n",
    "Notice how the fields are more meaningful than the fields in the bronze data set.\n",
    "\n",
    "Notice that we are explicitly creating a DataFrame. This is so we can pass it to the `display` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>wikipedia</th><th>isAnonymous</th><th>namespace</th><th>page</th><th>pageURL</th><th>geocoding</th><th>timestamp</th><th>user</th></tr></thead><tbody><tr><td>en</td><td>false</td><td>article</td><td>Cleeve Hill, Gloucestershire</td><td>http://en.wikipedia.org/wiki/Cleeve_Hill,_Gloucestershire</td><td>List(null, null, null, null, null, null, null)</td><td>2020-04-15T10:51:29.000+0000</td><td>Imaginatorium</td></tr><tr><td>en</td><td>false</td><td>article</td><td>Harmonic coordinates</td><td>http://en.wikipedia.org/wiki/Harmonic_coordinates</td><td>List(null, null, null, null, null, null, null)</td><td>2020-04-15T10:51:30.000+0000</td><td>OAbot</td></tr><tr><td>en</td><td>false</td><td>user talk</td><td>User talk:2405:6E00:2ED6:3D00:7CF6:D68E:362B:9DFC</td><td>http://en.wikipedia.org/wiki/User_talk:2405:6E00:2ED6:3D00:7CF6:D68E:362B:9DFC</td><td>List(null, null, null, null, null, null, null)</td><td>2020-04-15T10:51:33.000+0000</td><td>Passengerpigeon</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "silverDF = spark.sql(\"SELECT * FROM delta.`{}` limit 3\".format(silverPath))\n",
    "display(silverDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SUMMARY (aka \"gold\") level data \n",
    "\n",
    "Summary queries can take a long time.\n",
    "\n",
    "Instead of running the below query off the data under `silverPath`, let's create a summary query.\n",
    "\n",
    "We are interested in a breakdown of which countries that are producing anonymous edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc, count\n",
    "\n",
    "goldDF = (spark.readStream\n",
    "  .format(\"delta\")\n",
    "  .load(silverPath)\n",
    "  .withColumn(\"countryCode\", col(\"geocoding.countryCode3\"))\n",
    "  .filter(col(\"namespace\") == \"article\")\n",
    "  .filter(col(\"countryCode\") != \"null\")\n",
    "  .filter(col(\"isAnonymous\") == True)\n",
    "  .groupBy(col(\"countryCode\"))\n",
    "  .count() \n",
    "  .withColumnRenamed(\"count\", \"total\")\n",
    "  .orderBy(col(\"total\").desc())\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Visualizations (aka \"platinum\" level) \n",
    "\n",
    "#### Mapping Anonymous Editors' Locations\n",
    "\n",
    "Use that geocoding information to figure out the countries associated with the editors.\n",
    "\n",
    "When you run the query, the default is a (live) html table.\n",
    "\n",
    "In order to create a slick world map visualization of the data, you'll need to click on the item below.\n",
    "\n",
    "Under <b>Plot Options</b>, use the following:\n",
    "* <b>Keys:</b> `countryCode`\n",
    "* <b>Values:</b> `total`\n",
    "\n",
    "In <b>Display type</b>, use <b>World Map</b> and click <b>Apply</b>.\n",
    "\n",
    "\n",
    "By invoking a `display` action on a DataFrame created from a `readStream` transformation, we can generate a LIVE visualization!\n",
    "\n",
    "Keep an eye on the plot for a minute or two and watch the colors change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Visualizations (aka \"platinum\" level) \n",
    "\n",
    "LIVE means you can see the colors change if you watch the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>countryCode</th><th>total</th></tr></thead><tbody><tr><td>GBR</td><td>41</td></tr><tr><td>USA</td><td>24</td></tr><tr><td>AUS</td><td>7</td></tr><tr><td>IND</td><td>6</td></tr><tr><td>BEL</td><td>5</td></tr><tr><td>PHL</td><td>5</td></tr><tr><td>ITA</td><td>5</td></tr><tr><td>IDN</td><td>4</td></tr><tr><td>DEU</td><td>4</td></tr><tr><td>MYS</td><td>3</td></tr><tr><td>EGY</td><td>3</td></tr><tr><td>UKR</td><td>3</td></tr><tr><td>NZL</td><td>3</td></tr><tr><td>HKG</td><td>3</td></tr><tr><td>CAN</td><td>2</td></tr><tr><td>NOR</td><td>2</td></tr><tr><td>SAU</td><td>1</td></tr><tr><td>PER</td><td>1</td></tr><tr><td>CZE</td><td>1</td></tr><tr><td>SGP</td><td>1</td></tr><tr><td>EST</td><td>1</td></tr><tr><td>BLR</td><td>1</td></tr><tr><td>SRB</td><td>1</td></tr><tr><td>ROU</td><td>1</td></tr><tr><td>KOR</td><td>1</td></tr><tr><td>GRC</td><td>1</td></tr><tr><td>IRN</td><td>1</td></tr><tr><td>TWN</td><td>1</td></tr><tr><td>RUS</td><td>1</td></tr><tr><td>AUT</td><td>1</td></tr><tr><td>ZAF</td><td>1</td></tr><tr><td>ESP</td><td>1</td></tr><tr><td>PRT</td><td>1</td></tr><tr><td>ISL</td><td>1</td></tr><tr><td>ARE</td><td>1</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(goldDF, streamName = goldStreamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream gold_stream_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Wait until the stream is done initializing...\n",
    "untilStreamIsReady(goldStreamName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are all done, make sure to stop all the streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Stopping the stream gold_stream_ps.\n",
       "The stream gold_stream_ps was stopped.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopAllStreams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Cleanup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Questions\n",
    "**Q:** What is the difference between Lambda and Databricks Delta architecture?<br>\n",
    "**A:** The principal difference is that \n",
    "* In a Databricks Delta architecture, output queries can be performed on streaming and historical data at the same time.\n",
    "* In a Lambda architecture, streaming and historical data are treated as two separate branches feeding output queries.\n",
    "\n",
    "**Q:** What is role of raw (bronze) tables?<br>\n",
    "**A:** Raw tables capture streaming and historical data into a permanent record (streaming data tends to disappear after a short while). Though, it's generally hard to query.\n",
    "\n",
    "**Q:** What is role of query (silver) tables?<br>\n",
    "**A:** Query tables consist of normalized raw data that is easier to query.\n",
    "\n",
    "**Q:** What is role of summary (gold) tables?<br>\n",
    "**A:** Summary tables contain aggregated key business metrics that are queried frequently, but the silver queries themselves would take too long."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Delta 07 - Architecture",
  "notebookId": 3227357976395222
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
