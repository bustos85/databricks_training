{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Setup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up relevant paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataPath = \"dbfs:/mnt/training/definitive-guide/data/activity-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Concepts\n",
    "\n",
    "<b>Stream processing</b> is where you continuously incorporate new data into a data lake and compute results.\n",
    "\n",
    "The data is coming in faster than it can be consumed.\n",
    "\n",
    "Treat a <b>stream</b> of data as a table to which data is continously appended. \n",
    "\n",
    "In this course we are assuming Databricks Structured Streaming, which uses the DataFrame API. \n",
    "\n",
    "There are other kinds of streaming systems.\n",
    "\n",
    "Examples are bank card transactions, Internet of Things (IoT) device data, and video game play events. \n",
    "\n",
    "Data coming from a stream is typically not ordered in any way.\n",
    "\n",
    "A streaming system consists of \n",
    "* <b>Input source</b> such as Kafka, Azure Event Hub, files on a distributed system or TCP-IP sockets\n",
    "* <b>Sinks</b> such as Kafka, Azure Event Hub, various file formats, `foreach` sinks, console sinks or memory sinks\n",
    "\n",
    "### Streaming and Databricks Delta\n",
    "\n",
    "In streaming, the problems of traditional data pipelines are exacerbated. \n",
    "\n",
    "Specifically, with frequent meta data refreshes, table repairs and accumulation of small files on a secondly- or minutely-basis!\n",
    "\n",
    "Many small files result because data (may be) streamed in at low volumes with short triggers.\n",
    "\n",
    "Databricks Delta is uniquely designed to address these needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ Stream using Databricks Delta\n",
    "\n",
    "The `readStream` method is similar to a transformation that outputs a DataFrame with specific schema specified by `.schema()`. \n",
    "\n",
    "Each line of the streaming data becomes a row in the DataFrame once `writeStream` is invoked.\n",
    "\n",
    "In this lesson, we limit flow of stream to one file per trigger with `option(\"maxFilesPerTrigger\", 1)` so that you do not exceed file quotas you may have on your end. The default value is 1000.\n",
    "\n",
    "Notice that nothing happens until you engage an action, i.e. a `writeStream` operation a few cells down.\n",
    "\n",
    "Do some data normalization as well:\n",
    "* Convert `Arrival_Time` to `timestamp` format.\n",
    "* Rename `Index` to `User_ID`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "static = spark.read.json(dataPath)\n",
    "dataSchema = static.schema\n",
    "\n",
    "deltaStreamWithTimestampDF = (spark\n",
    "  .readStream\n",
    "  .option(\"maxFilesPerTrigger\", 1)\n",
    "  .schema(dataSchema)\n",
    "  .json(dataPath)\n",
    "  .withColumnRenamed('Index', 'User_ID')\n",
    "  .selectExpr(\"*\",\"cast(cast(Arrival_Time as double)/1000 as timestamp) as event_time\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WRITE Stream using Databricks Delta\n",
    "\n",
    "#### General Notation\n",
    "Use this format to write a streaming job to a Databricks Delta table.\n",
    "\n",
    "> `(myDF` <br>\n",
    "  `.writeStream` <br>\n",
    "  `.format(\"delta\")` <br>\n",
    "  `.option(\"checkpointLocation\", somePath)` <br>\n",
    "  `.outputMode(\"append\")` <br>\n",
    "  `.table(\"my_table\")` or `.start(path)` <br>\n",
    "`)`\n",
    "\n",
    "If you use the `.table()` notation, it will write output to a default location. \n",
    "* This would be in parquet files under `/user/hive/warehouse/default.db/my_table`\n",
    "\n",
    "In this course, we want everyone to write data to their own directory; so, instead, we use the `.start()` notation.\n",
    "\n",
    "#### Output Modes\n",
    "Notice, besides the \"obvious\" parameters, specify `outputMode`, which can take on these values\n",
    "* `append`: add only new records to output sink\n",
    "* `complete`: rewrite full output - applicable to aggregations operations\n",
    "* `update`: update changed records in place\n",
    "\n",
    "#### Checkpointing\n",
    "\n",
    "When defining a Delta streaming query, one of the options that you need to specify is the location of a checkpoint directory.\n",
    "\n",
    "`.writeStream.format(\"delta\").option(\"checkpointLocation\", <path-to-checkpoint-directory>) ...`\n",
    "\n",
    "This is actually a structured streaming feature. It stores the current state of your streaming job.\n",
    "\n",
    "Should your streaming job stop for some reason and you restart it, it will continue from where it left off.\n",
    "\n",
    "If you do not have a checkpoint directory, when the streaming job stops, you lose all state around your streaming job and upon restart, you start from scratch.\n",
    "\n",
    "Also note that every streaming job should have its own checkpoint directory: no sharing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Do Some Streaming\n",
    "\n",
    "In the cell below, we write streaming query to a Databricks Delta table. \n",
    "\n",
    "Notice how we do not need to specify a schema: it is inferred from the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to help us manage our streams better, we will make use of **`untilStreamIsReady()`**, **`stopAllStreams()`** and define the following, **`myStreamName`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "myStreamName = \"lesson05_ps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writePath =      workingDir + \"/output.delta\"\n",
    "checkpointPath = workingDir + \"/output.checkpoint\"\n",
    "\n",
    "deltaStreamingQuery = (deltaStreamWithTimestampDF\n",
    "  .writeStream\n",
    "  .format(\"delta\")\n",
    "  .option(\"checkpointLocation\", checkpointPath)\n",
    "  .outputMode(\"append\")\n",
    "  .queryName(myStreamName)\n",
    "  .start(writePath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See list of active streams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">lesson05_ps: 760e31e4-ff0f-4851-a2c3-8cdca56b91a6\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for s in spark.streams.active:\n",
    "  print(\"{}: {}\".format(s.name, s.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until stream is done initializing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream lesson05_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untilStreamIsReady(myStreamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Stopping the stream lesson05_ps.\n",
       "The stream lesson05_ps was stopped.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopAllStreams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Table-to-Table Stream\n",
    "\n",
    "Here we read a stream of data from from `writePath` and write another stream to `activityPath`.\n",
    "\n",
    "The data consists of a grouped count of `gt` events.\n",
    "\n",
    "Make sure the stream using `deltaStreamingQuery` is still running!\n",
    "\n",
    "To perform an aggregate operation, what kind of `outputMode` should you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "activityPath   = workingDir + \"/activityCount.delta\"\n",
    "checkpointPath = workingDir + \"/activityCount.checkpoint\"\n",
    "\n",
    "activityCountsQuery = (spark.readStream\n",
    "  .format(\"delta\")\n",
    "  .load(str(writePath))   \n",
    "  .groupBy(\"gt\")\n",
    "  .count()\n",
    "  .writeStream\n",
    "  .format(\"delta\")\n",
    "  .option(\"checkpointLocation\", checkpointPath)\n",
    "  .outputMode(\"complete\")\n",
    "  .queryName(myStreamName)\n",
    "  .start(activityPath)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait until stream is done initializing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream lesson05_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untilStreamIsReady(myStreamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Tests passed!\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "activityQueryTruth = spark.streams.get(activityCountsQuery.id).isActive\n",
    "\n",
    "dbTest(\"Delta-05-activityCountsQuery\", True, activityQueryTruth)\n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Stopping the stream lesson05_ps.\n",
       "The stream lesson05_ps was stopped.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopAllStreams()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "\n",
    "Plot the occurrence of all events grouped by `gt`.\n",
    "\n",
    "Under <b>Plot Options</b>, use the following:\n",
    "* <b>Series Groupings:</b> `gt`\n",
    "* <b>Values:</b> `count`\n",
    "\n",
    "In <b>Display type</b>, use <b>Bar Chart</b> and click <b>Apply</b>.\n",
    "\n",
    "In the cell below, we use the `withWatermark` and `window` methods, which aren't covered in this course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>window</th><th>gt</th><th>count</th><th>hour</th></tr></thead><tbody><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>walk</td><td>14268</td><td>10</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>stairsup</td><td>8685</td><td>10</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>sit</td><td>9827</td><td>13</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>null</td><td>10909</td><td>13</td></tr><tr><td>List(2015-02-23T14:00:00.000+0000, 2015-02-23T15:00:00.000+0000)</td><td>stairsdown</td><td>9576</td><td>14</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>walk</td><td>14589</td><td>13</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>bike</td><td>10008</td><td>10</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>bike</td><td>27422</td><td>14</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>walk</td><td>14220</td><td>14</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>stairsdown</td><td>9403</td><td>13</td></tr><tr><td>List(2015-02-23T14:00:00.000+0000, 2015-02-23T15:00:00.000+0000)</td><td>walk</td><td>4034</td><td>14</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>walk</td><td>18394</td><td>13</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>bike</td><td>7767</td><td>12</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>stairsdown</td><td>11576</td><td>12</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>stairsup</td><td>14262</td><td>12</td></tr><tr><td>List(2015-02-23T14:00:00.000+0000, 2015-02-23T15:00:00.000+0000)</td><td>stairsup</td><td>10350</td><td>14</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>stairsdown</td><td>10346</td><td>11</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>stairsdown</td><td>16400</td><td>13</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>stairsup</td><td>10840</td><td>11</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>bike</td><td>11907</td><td>11</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>stairsup</td><td>9833</td><td>14</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>walk</td><td>12348</td><td>12</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>walk</td><td>27580</td><td>12</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>stand</td><td>10431</td><td>12</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>sit</td><td>23526</td><td>12</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>null</td><td>15756</td><td>10</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>sit</td><td>12969</td><td>10</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>stand</td><td>20668</td><td>11</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>stand</td><td>12087</td><td>14</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>bike</td><td>12141</td><td>12</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>stand</td><td>22275</td><td>13</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>stand</td><td>9972</td><td>13</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>null</td><td>15916</td><td>12</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>bike</td><td>9018</td><td>13</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>stairsdown</td><td>9053</td><td>12</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>stairsup</td><td>19305</td><td>13</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>sit</td><td>12546</td><td>14</td></tr><tr><td>List(2015-02-24T12:00:00.000+0000, 2015-02-24T13:00:00.000+0000)</td><td>stand</td><td>15143</td><td>12</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>null</td><td>7003</td><td>12</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>stairsup</td><td>9731</td><td>13</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>sit</td><td>13169</td><td>11</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>walk</td><td>13871</td><td>11</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>stairsup</td><td>11061</td><td>12</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>stairsdown</td><td>8995</td><td>14</td></tr><tr><td>List(2015-02-23T14:00:00.000+0000, 2015-02-23T15:00:00.000+0000)</td><td>null</td><td>2661</td><td>14</td></tr><tr><td>List(2015-02-24T11:00:00.000+0000, 2015-02-24T12:00:00.000+0000)</td><td>null</td><td>11336</td><td>11</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>null</td><td>10570</td><td>13</td></tr><tr><td>List(2015-02-23T14:00:00.000+0000, 2015-02-23T15:00:00.000+0000)</td><td>bike</td><td>9381</td><td>14</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>stairsdown</td><td>8937</td><td>10</td></tr><tr><td>List(2015-02-23T13:00:00.000+0000, 2015-02-23T14:00:00.000+0000)</td><td>sit</td><td>26969</td><td>13</td></tr><tr><td>List(2015-02-24T14:00:00.000+0000, 2015-02-24T15:00:00.000+0000)</td><td>null</td><td>19882</td><td>14</td></tr><tr><td>List(2015-02-23T10:00:00.000+0000, 2015-02-23T11:00:00.000+0000)</td><td>stand</td><td>11888</td><td>10</td></tr><tr><td>List(2015-02-24T13:00:00.000+0000, 2015-02-24T14:00:00.000+0000)</td><td>bike</td><td>9531</td><td>13</td></tr><tr><td>List(2015-02-23T12:00:00.000+0000, 2015-02-23T13:00:00.000+0000)</td><td>sit</td><td>11772</td><td>12</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "from pyspark.sql.functions import hour, window, col\n",
    "\n",
    "countsDF = (deltaStreamWithTimestampDF      \n",
    "  .withWatermark(\"event_time\", \"180 minutes\")\n",
    "  .groupBy(window(\"event_time\", \"60 minute\"), \"gt\")\n",
    "  .count()\n",
    ")\n",
    "\n",
    "display(countsDF.withColumn('hour',hour(col('window.start'))), streamName = myStreamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">The stream lesson05_ps is active and ready.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "untilStreamIsReady(myStreamName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Tests passed!\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TEST - Run this cell to test your solution.\n",
    "schemaStr = str(countsDF.schema)\n",
    "\n",
    "dbTest(\"Assertion #1\", 3, len(countsDF.columns))\n",
    "dbTest(\"Assertion #2\", True, \"(gt,StringType,true)\" in schemaStr) \n",
    "dbTest(\"Assertion #3\", True, \"(count,LongType,false)\" in schemaStr) \n",
    "\n",
    "dbTest(\"Assertion #5\", True, \"window,StructType\" in schemaStr)\n",
    "dbTest(\"Assertion #6\", True, \"(start,TimestampType,true)\" in schemaStr) \n",
    "dbTest(\"Assertion #7\", True, \"(end,TimestampType,true)\" in schemaStr) \n",
    "\n",
    "print(\"Tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Stopping the stream lesson05_ps.\n",
       "The stream lesson05_ps was stopped.\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stopAllStreams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"./Includes/Classroom-Cleanup\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Questions\n",
    "**Q:** Why is Databricks Delta so important for a data lake that incorporates streaming data?<br>\n",
    "**A:** Frequent meta data refreshes, table repairs and accumulation of small files on a secondly- or minutely-basis!\n",
    "\n",
    "**Q:** What happens if you shut off your stream before it has fully initialized and started and you try to `CREATE TABLE .. USING DELTA` ? <br>\n",
    "**A:** You will get this: `Error in SQL statement: AnalysisException: The user specified schema is empty;`.\n",
    "\n",
    "**Q:** When you do a write stream command, what does this option do `outputMode(\"append\")` ?<br>\n",
    "**A:** This option takes on the following values and their respective meanings:\n",
    "* <b>append</b>: add only new records to output sink\n",
    "* <b>complete</b>: rewrite full output - applicable to aggregations operations\n",
    "* <b>update</b>: update changed records in place\n",
    "\n",
    "**Q:** What happens if you do not specify `option(\"checkpointLocation\", pointer-to-checkpoint directory)`?<br>\n",
    "**A:** When the streaming job stops, you lose all state around your streaming job and upon restart, you start from scratch.\n",
    "\n",
    "**Q:** How do you view the list of active streams?<br>\n",
    "**A:** Invoke `spark.streams.active`.\n",
    "\n",
    "**Q:** How do you verify whether `streamingQuery` is running (boolean output)?<br>\n",
    "**A:** Invoke `spark.streams.get(streamingQuery.id).isActive`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Delta 05 - Streaming",
  "notebookId": 3227357976395814
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
